---
title: The Physics Engine (Gazebo)
sidebar_label: 1. Gazebo Physics
id: gazebo-physics
description: Learn about Gazebo, URDF/SDF, and simulating robot physics.
custom_edit_url: null
experience_level: Beginner
---

# The Physics Engine: Gazebo

<HeroBox title="Entering The Matrix" variant="blue">
  <p>
    Before your robot walks in the real world, it needs to learn how to walk in a digital one. <strong>Gazebo</strong> is your training ground, a high-fidelity simulator where the laws of physics are strictly enforced.
  </p>
</HeroBox>

## Learning Objectives

By the end of this chapter, you will be able to:

-   Understand Gazebo as a physics simulator for robotics.
-   Distinguish between "Visual Geometry" and "Collision Geometry."
-   Define a robot's inertial properties using advanced URDF/SDF.
-   Simulate LiDAR and Depth Camera sensors in Gazebo.

## 1. The Environment: Gazebo

**Gazebo** is a powerful 3D robotics simulator that allows you to accurately test your algorithms, design robots, and perform training in a virtual world. It provides a robust physics engine, high-quality graphics, and convenient interfaces.

### Visual Geometry vs. Collision Geometry
*   **Visual Geometry**: What your robot *looks* like. This is for rendering and display (e.g., in Rviz or Gazebo's GUI). It can be complex meshes for realism.
*   **Collision Geometry**: What your robot *collides* with. This is a simplified representation (e.g., boxes, cylinders, spheres) used by the physics engine for performance. Complex meshes for collision detection are computationally expensive.

### Setup: Launching an Empty World
To begin, you can launch a basic empty world in Gazebo.

**CLI Command (from `context7`: /gazebosim/docs)**:
```bash
ign gazebo -r empty.sdf
```
Or, if using ROS 2 integration:
**ROS 2 Launch Command (from `context7`: /gazebosim/docs)**:
```bash
ros2 launch ros_gz_sim gz_sim.launch.py gz_args:=-r empty.sdf
```

## 2. Robot Description: Advanced URDF & SDF

While URDF (Unified Robot Description Format) is great for kinematic descriptions, **SDF** (Simulation Description Format) is often preferred for Gazebo as it allows for more detailed simulation parameters, including full world descriptions and advanced sensor definitions.

### Physics Parameters: Mass, Inertia, and Friction
For accurate simulation, your robot's physical properties must be correctly defined.

#### Inertial Properties
The `<inertial>` tag defines the mass and inertia matrix of a robot's link. Incorrect values here can lead to unstable or explosive simulations.

**XML Snippet (from `context7`: /gazebosim/docs)**:
```xml
<inertial>
    <mass>1.14395</mass>
    <inertia>
        <ixx>0.095329</ixx>
        <ixy>0</ixy>
        <ixz>0</ixz>
        <iyy>0.381317</iyy>
        <iyz>0</iyz>
        <izz>0.476646</izz>
    </inertia>
</inertial>
```

#### Friction
In Gazebo, friction is a property defined in the `<friction>` tag within the `<surface>` element of a `<collision>`.

<SimToRealWarning>
  In Gazebo, you can define "perfect friction" or even negative friction. In the real world, your robot will **slip**. Simulation will never perfectly replicate the complexities of real-world friction. Always account for discrepancies when transferring algorithms from sim to real.
</SimToRealWarning>

### Activity: The Wobbly Bot

Create a simple box robot with a wheel. Start by giving the box a mass of 1kg but an inertia tensor of all zeros. Observe how the robot behaves (likely vibrating uncontrollably or flying away). Then, use online tools (like a mass properties calculator) to compute the correct inertia values for a simple box and update your SDF.

## 3. Sensor Simulation

Giving your digital twin virtual eyes and ears is crucial for developing perception algorithms.

### LiDAR (Ray-Casting)
LiDAR sensors are simulated by casting rays into the environment and detecting intersections. The `gpu_lidar` type is optimized for performance.

**XML Snippet (from `context7`: /gazebosim/docs)**:
```xml
<sensor name="gpu_lidar" type="gpu_lidar">
  <always_on>true</always_on>
  <visualize>true</visualize>
  <update_rate>10</update_rate>
  <ray>
    <scan>
      <horizontal>
        <samples>640</samples>
        <resolution>1</resolution>
        <min_angle>-1.396263</min_angle>
        <max_angle>1.396263</max_angle>
      </horizontal>
      <vertical>
        <samples>1</samples>
        <resolution>0.01</resolution>
        <min_angle>0</min_angle>
        <max_angle>0</max_angle>
      </vertical>
    </scan>
    <range>
      <min>0.08</min>
      <max>10.0</max>
      <resolution>0.01</resolution>
    </range>
  </ray>
  <plugin filename="libignition-gazebo-sensors-system.so" name="ignition::gazebo::systems::Sensors">
      <render_engine>ogre2</render_engine>
  </plugin>
</sensor>
```

### Depth Camera
Depth cameras provide both RGB (color) and depth (distance) information, crucial for object recognition and navigation.

**XML Snippet (from `context7`: /gazebosim/docs)**:
```xml
<sensor name="camera" type="camera">
  <always_on>true</always_on>
  <visualize>true</visualize>
  <update_rate>30</update_rate>
  <topic>camera/image_raw</topic>
  <gz_frame_id>camera_rgb_frame</gz_frame_id>
  <camera name="intel_realsense_r200">
    <camera_info_topic>camera/camera_info</camera_info_topic>
    <image>
      <width>640</width>
      <height>480</height>
      <format>R8G8B8</format>
    </image>
    <depth_camera>
      <output>depth_image</output>
    </depth_camera>
    <noise>
      <type>gaussian</type>
      <mean>0.0</mean>
      <stddev>0.007</stddev>
    </noise>
  </camera>
  <plugin filename="libignition-gazebo-sensors-system.so" name="ignition::gazebo::systems::Sensors">
      <render_engine>ogre2</render_engine>
  </plugin>
</sensor>
```

---

**Next:** Let's look at how **Unity** can be used for high-fidelity rendering with ROS 2.